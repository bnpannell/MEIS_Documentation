% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\title{California Military Economic Impact Study Process Guide}
\author{Britnee Pannell \& Sumeet Bedi}
\date{2022-01-21}

\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={California Military Economic Impact Study Process Guide},
  pdfauthor={Britnee Pannell \& Sumeet Bedi},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\nocite{*}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

The California Military Economic Impact Study report series began in 2018, when the California Governor's Office of Planning \& Research and the Governor's Military Council requested the California Research Bureau (CRB, a unit of the California State Library) to conduct this study. This report provides detailed statewide and localized economic impacts of federal national security activity in the state of California. The federal agencies identified as relevant to national security includes the Departments of Defense (DOD), Homeland Security (DHS), Veterans Affairs (VA), and specified sub-agencies of The Department of Energy (DOE). The type of economic activity detailed includes spending (contracts, grants, veterans' benefits, and SmartPay charge card) and employment data (civilian and military). The first report, published in August 2018, utilized federal fiscal year 2016 data, while the second report, published in December 2019, used fiscal year 2018 data.

Following these 2 reports, the Office of Planning \& Research and the CRB secured grant funding from the DOD to support two full-time equivalent (FTE) positions to develop supplemental reports that help localize the economic impacts detailed in the statewide report. In December 2020, the CRB produced the 2020 California Military Economic Impact Study, and followed this third edition of the statewide report with 2 first-time supplements that discuss the economic impacts in every county and congressional district in California. In December 2021, the Research Bureau completed the fourth version of the statewide report as well as the second edition of the county and congressional district supplements. After completion of the second round of supplements, the CRB was tasked with producing this process guide document.

This process guide and supporting documentation were developed in order to allow other states to replicate the methodology of this study for their respective geography of interest. Additionally, this documentation serves to provide the rationale behind how the data was gathered, wrangled, and analyzed in order to justify the conclusions in our main reports.

\hypertarget{software-requirements}{%
\chapter{Software Requirements}\label{software-requirements}}

To recreate California's study or to perform studies in additional areas, specialized software is needed to obtain and process Federal data. Fortunately all software is free and available online.(Where possible, make sure to use the most recent and fully updated versions of the software).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The R coding language from \href{https://cloud.r-project.org/}{cloud.r-project.org}. This language is used to obtain and process data.
\item
  RStudio Desktop from \href{https://rstudio.com/products/rstudio/download/\#download}{rstudio.com}. RStudio is the integrated development environment (IDE) used to run R scripts and develop code.
\item
  Git from \href{https://git-scm.com/downloads}{git-scm.com}. A comprehensive guide to installing Git is available at \href{https://happygitwithr.com/install-git.html}{happygitwithr.com}. Git allows version control of edits across a multi-person team of researchers.
\item
  If a Github account is needed, one can sign up and register at \url{https://github.com/}. Individual free plans are available, as well as \href{https://help.github.com/en/articles/applying-for-an-educator-or-researcher-discount}{free upgrades} for qualifying academic purposes.Github is used to develop and host this project.
\end{enumerate}

\hypertarget{download-necessary-r-packages}{%
\section{Download Necessary R Packages}\label{download-necessary-r-packages}}

dplyr, httr, jsonlite, openxlsx, readxl, tidyverse (double check that our code actually uses all of these packages)

The next section details data necessary to complete this project as well as how to obtain it.

\hypertarget{data-requirements}{%
\chapter{Data Requirements}\label{data-requirements}}

This section details how to obtain each data type, whose categories are defined in the ``requirements'' section. The data is broken out into 3 types: employment, USAspending, and all other additional data. There is no guarantee that the data sources described below will exist in this form indefinitely, so care will be taken to keep this document as up to date as possible.

\hypertarget{employment-data}{%
\section{Employment Data}\label{employment-data}}

This report focused on 2 types of employment data: civilian and military. These 2 employment data types were found on 2 separate websites:

\textbf{Civilian employment} was obtained from the \href{https://www.fedscope.opm.gov/}{Office of Personnel Management's (OPM) FedScope website}, which provides federal workforce data. From this link, one can click on ``Employment'' under the ``Status Data'' bullet point to access quarterly employment data cubes. Given that the report focuses on federal fiscal years, the employment data of interest is of Quarter 3 of a given year (i.e.~September). When one clicks on a September cube of their desired year, one can filter the data by agency type (``Cabinet Level'') and location (``United States'' and a state of one's choice) in order to get the civilian employment numbers for the Departments of Defense (which is an aggregate of the Air Force, Army, Defense, and Navy cabinet agencies), Homeland Security, Veterans Affairs, and Energy. This data can be exported out as a PDF, CSV, or Excel file.

\textbf{Military employment} was obtained from the \href{https://dwp.dmdc.osd.mil/dwp/app/main}{Defense Manpower Data Center (DMDC) website}, which serves under the Office of the Secretary of Defense. From this link, one can hover over to DoD Data/Reports and select ``Statistics \& Reports''. On this page, scroll to the ``DoD Personnel, Workforce Reports \& Publications'' text, and click on its hyperlink. \href{https://dwp.dmdc.osd.mil/dwp/app/dod-data-reports/workforce-reports}{This opens up a new window to access the military employment data}. Similar to civilian employment, the data of interest is from September of a given year. One can scroll to the section ``Military and Civilian Personnel by Service/Agency by State/Country (Updated Quarterly)'', and download the Excel file for September of their desired year.

\hypertarget{usaspending-data}{%
\section{USASpending Data}\label{usaspending-data}}

This report utilized \href{https://www.usaspending.gov/}{USAspending.gov} for a large majority of the direct spending done by federal national security agencies in California. The spending types obtained from this site include contracts and grants for DOD, DHS, VA and DOE, as well as direct payments from VA (i.e.~veterans' benefits). From this link, one can hover over to ``Download'' and click on ``Custom Award Data''. \href{https://www.usaspending.gov/download_center/custom_award_data}{On this webpage}, one can select the appropriate spending award types (contracts, grants, and/or direct payments), awarding agency (DOD, DHS, VA, DOE), recipient location (United States for ``Country'', and a specific state should you want to filter the data further), action date range (a fiscal year ``FY 20XX''), and file format. This download process must be done once per agency.

For obtaining USAspending data, we have developed code that automates this entire process and easily captures all USAspending data in one instance. Please refer to our methods section of this process guide for more details.

\hypertarget{additional-data}{%
\section{Additional Data}\label{additional-data}}

\hypertarget{smartpay-data-via-foia}{%
\subsection{SmartPay Data via FOIA}\label{smartpay-data-via-foia}}

The remaining portion of direct spending detailed in these reports was SmartPay, a charge card program for federal employees. In order to obtain this data, Freedom of Information Act requests (commonly known as FOIAs) were sent out to the federal national security agencies.

For more information about SmartPay, please visit the \href{https://www.gsa.gov/travel/plan-book/gsa-smartpay}{General Services Administration's (GSA) SmartPay website}.

\hypertarget{data-obtained-online}{%
\subsection{Data Obtained Online}\label{data-obtained-online}}

A variety of data sources needed to be obtained online in order to assist with the data processing for this report. This includes:

\begin{itemize}
\item
  \href{https://www.gsa.gov/policy-regulations/policy/real-property-policy/asset-management/federal-real-property-profile-frpp/federal-real-property-public-data-set}{Federal Real Public Property data} from the GSA. At this link, the GSA provides an Excel file that breaks down how much federal property is spread out across the United States. This data is used to help localize the number of statewide DHS and VA civilian employees across counties and districts.
\item
  \href{https://data.census.gov/cedsci/}{American Community Survey data} from the Census Bureau. At this link, type into the search bar at the center of the webpage ``DP03''. This returns a table of ``Selected economic characteristics''. From this table, one can filter to the appropriate geography (state, county, congressional district, etc.), year, and such to download into an Excel file. This data is used to help localize the number of statewide military personnel across counties and districts.
\item
  \href{https://support.implan.com/hc/en-us/articles/360034896614-546-Industries-Conversions-Bridges-Construction-2018-Data}{NAICS to IMPLAN crosswalk} from IMPLAN. At this link, IMPLAN provides a variety of crosswalks that one can use to relate data from other source to IMPLAN's 546 industries. On this page, one can go to the second heading titled ``2017 NAICS to IMPLAN 546 Industries'' and download the Excel file. This crosswalk is utilized to help relate the USAspending contracts data to IMPLAN sectors in order to run that spending data through the IMPLAN software.
\end{itemize}

\hypertarget{data-provided-rawself-made}{%
\subsection{Data Provided Raw/Self-Made}\label{data-provided-rawself-made}}

The repository contains some raw data files that we have prepared for this project. Specific instructions on how to access this repository and utilize these raw data sources are explained in the next section.

\hypertarget{setting-up-the-repository}{%
\chapter{Setting Up the Repository}\label{setting-up-the-repository}}

\hypertarget{obtain-repository}{%
\section{Obtain Repository}\label{obtain-repository}}

Instructions on how to get repo containing code and raw data provided to end users.

Include link to repo and specifically Readme.md file (won't be able to link this until that repo finds its forever home)

Do we want to have a chapter on just setting up the repo and running through each section and file it contains? AKA a data dictionary for the Repo? To insert before the methods section??
So maybe 2 additional sections

\hypertarget{data-dictionary-for-repository}{%
\chapter{Data Dictionary for Repository}\label{data-dictionary-for-repository}}

This section details each file contained in the code repository and a summary of what it is used for in the project. For a more detailed explanation, please see the ``Methods'' section. {[}add link later{]}

\hypertarget{meis_methodology-folder-change-name-later}{%
\section{MEIS\_Methodology Folder {[}CHANGE NAME LATER{]}}\label{meis_methodology-folder-change-name-later}}

This is the main folder, containing all data in the repository.
- .gitignore: Lists files that will be ignored when using Git to synchronize updates to repository.
- .Rhistory: Contains the history of commands given by a user in an R Session
- LICENSE: Contains licensing information for the repository
- MEIS\_Methodology.Rproj: the R project package used to open the repository in an IDE such as RStudio.
- README.md: The first file you should read in any repository. Contains basic installation information, information on the repository contents and instructions on how to use the repository.
- parameters.R: Contains all variables that may require user editing in order for code to run properly. Use of this file is documented in the README.md file.
- run\_analysis\_master.R: The newest version of the code to process the Federal data. Currently this file is in development for the upcoming 2022 version of this project.
- DEPRECATED\_run\_analysis\_master.R: This file contains the script used for the 2021 project. This process guide pertains mostly to the code running from this master script.

\hypertarget{data-folder}{%
\section{data Folder}\label{data-folder}}

This is the folder designed to hold data for this project.

\hypertarget{raw-folder}{%
\subsection{raw Folder}\label{raw-folder}}

This folder contains all raw data provided to the user to aid them in analyzing Federal data for their projects.

\hypertarget{temp-folder}{%
\subsection{temp Folder}\label{temp-folder}}

This folder holds all files that are made while either master script is running. These files are deleted when the final output is finished being processed.

\hypertarget{output-folder}{%
\section{output Folder}\label{output-folder}}

This folder holds all of the final output files needed by IMPLAN in order to complete this project. New output files will get created and input to this folder while running scripts from this repository.
- placeholder.txt: This file prevents Github from deleting the output folder, as it is empty by default.

\hypertarget{src-folder}{%
\section{src Folder}\label{src-folder}}

This folder contains all script files needed by the master script when it is running. Scripts in this folder may be used by either of the master scripts contained in this repository. DO NOT MODIFY ANY OF THESE FILES.

\hypertarget{deprecated-folder}{%
\subsection{deprecated Folder}\label{deprecated-folder}}

This folder contains all scripts that are only used by the DEPRECATED\_run\_analysis\_master.R script. DO NOT MODIFY ANY OF THESE FILES.

\hypertarget{methods}{%
\chapter{Methods}\label{methods}}

The following section details how to use the data and R code provided as well as an explanation of how the code works.

\hypertarget{reviewing-the-parameters-file}{%
\section{Reviewing the Parameters File}\label{reviewing-the-parameters-file}}

The first step in working with this code involves looking at the Parameters file. This file allows for alterations in the data analysis based on particular criteria that one may want to modify in their study, such as geography of interest, year, agencies of interest, and so forth. The default entries in the parameters file are based on this study of California.

\emph{Readme will eventually link to this section}

\hypertarget{making-user-specific-data-files}{%
\section{Making User Specific Data Files}\label{making-user-specific-data-files}}

Edit framework files in raw data of repo and move into appropriate section of repo.

Here is where you obtain your employment data and make the region specific file to read in those numbers (if we don't just put them in the parameters file?)

\hypertarget{processing-the-data}{%
\section{Processing the Data}\label{processing-the-data}}

After modifying the parameter files with the appropriate criteria and creating user specific data, one can begin working through the code to process the data and prepare it for IMPLAN. Refer to the deprecated\_run\_analysis\_master.R script to run through the data analysis process for this project.

\hypertarget{step-1-clearing-environment-and-loading-in-packages-and-parameters}{%
\subsection{Step 1: Clearing Environment, and Loading in Packages and Parameters}\label{step-1-clearing-environment-and-loading-in-packages-and-parameters}}

The first lines of code provide some housekeeping steps prior to running through the analysis. Line 4 allows the user to clear their global environment in RStudio, removing all previously defined or loaded packages, variables, values, etc. In running through the analysis wholesale, a good first step is to clear one's environment. Following this is lines 7-12, which load in the various RStudio library packages that are needed to perform this analysis. For more information on these packages, please refer to our References section (``ADD IN LINK TO REFERENCES AND/OR R PACKAGE DESCRIPTIONS''). The final housekeeping step involves line 15, which loads in the parameters file mentioned above.

\hypertarget{step-2-loading-in-functions}{%
\subsection{Step 2: Loading in Functions}\label{step-2-loading-in-functions}}

Lines 19-23 compose the second step of the data analysis process: loading in functions that standardize and simplify working through the data. Line 19 loads in a R script that performs a call to USAspending.gov's API in order to grab the relevant contract, grant, and direct payment spending data that we need for our analysis and download it into 2 files (1 for contracts, and 1 for grants/direct payments) at a specified file path location. In this case, the 2 CSV files obtained are downloaded into the data/temp folder. The parameters file is particularly important for this line of code, as the parameters file holds many of the filters that are used to sort what data is obtained from USAspending with this function. Line 20 loads in a function that is used to place additional filters on the obtained USAspending data and write the filtered data into CSV files. These additional filters are also outlined in the parameters file, but the actual filter function is not run until lines 26-30 (see step 3 for more details).

Line 21 loads in a function that concatenates the USAspending contract and grant data files into one dataframe in R, while also removing direct payments from that concatenation (as it is calculated separate from contracts and grants. more on this will be detailed below). The actual concatenate function is not run until lines 39 and 41 (see step 5 for more details). Line 22 loads in a function that splits out the concatenated USAspending dataframe by agency, taking out DOE data from the main dataframe. This is done because DOE's spending activity has been kept separate from the main data analysis of the project. The actual split function is not run until lines 44-47 (see step 6 for more details). Line 23 loads in a function that aggregates the USAspending and DOEspending dataframes by IMPLAN sector. This gets the contracts and grants spending data for 2 IMPLAN activity sheets complete: 1 for the main statewide analysis, and 1 for the DOE statewide analysis. The actual aggregate function is not run until lines 55-60 (see step 7 for more details).

\hypertarget{step-3-filtering-the-usaspending-data}{%
\subsection{Step 3: Filtering the USAspending Data}\label{step-3-filtering-the-usaspending-data}}

Lines 26-30 begin the third step of filtering down the USAspending data obtained from the API call. Lines 26 and 27 read in the downloaded contracts and grants/direct payments files (respectively) and assign them each to a variable. Lines 29 and 30 perform the filter\_usaspending function (that was loaded in at line 20) on each of those variables.

The filter\_usaspending function has five elements that must be referenced: file\_name, state, doe\_filters, filters, and out\_name.

\begin{itemize}
\tightlist
\item
  The \textbf{file\_name} element is a call to whichever data file we want to pass through to be filtered - in this case, the 2 USAspending CSVs that are defined in lines 26 and 27.
\item
  The \textbf{state} element is defined in our parameters, based on the state of interest for our study. In this case, that state is California. This element is added to ensure that the primary\_place\_of\_performance\_state is the same as the recipient\_state (which was filtered in our obtain\_usaspending function), thus ensuring that all data entries included in the analysis are in the state of interest for the study.
\item
  The \textbf{doe\_filters} element is defined in our parameters, based on \textbf{doe\_offices}. This element is included to filter out DOE spending done in the state that is not national security-related. The basis for this filter element is from a list of DOE sub-agencies that were demarcated as national security-related.
\item
  The \textbf{filters} element is defined in our parameters, based on \textbf{contract\_columns} and \textbf{grant\_columns}, respectively. This element is included to pare down the columns of data from the USAspending files to retain only the pertinent columns of data for our analysis.
\item
  The \textbf{out\_name} element is defined in our parameters, based on \textbf{c\_out\_name} and \textbf{g\_out\_name}, respectively. This element is included to give a naming convention for the files that get generated as a result of running the filter function.
\end{itemize}

After running the filter functions, 2 CSVs files should be generated in the data/temp folder, by the name defined from the \textbf{out\_name} element.

\hypertarget{step-4-error-checking-the-usaspending-data}{%
\subsection{Step 4: Error checking the USAspending Data}\label{step-4-error-checking-the-usaspending-data}}

Lines 34-35 begin the fourth step of checking for errors in the filtered USAspending data and fixing them. The process for error checking and fixing the data differs for contracts and grants.

\hypertarget{error-checking-usaspending-contracts}{%
\subsubsection{Error Checking USAspending Contracts}\label{error-checking-usaspending-contracts}}

Line 34

\hypertarget{error-checking-usaspending-grants}{%
\subsubsection{Error Checking USAspending Grants}\label{error-checking-usaspending-grants}}

Line 35

\hypertarget{step-5-concatenating-the-usaspending-data}{%
\subsection{Step 5: Concatenating the USAspending Data}\label{step-5-concatenating-the-usaspending-data}}

Lines 39 and 41

\hypertarget{step-6-splitting-doe-from-usaspending-data}{%
\subsection{Step 6: Splitting DOE from USAspending Data}\label{step-6-splitting-doe-from-usaspending-data}}

Lines 45, 47, and 48

\hypertarget{step-7-aggregating-the-spending-data-for-statewide-numbers}{%
\subsection{Step 7: Aggregating the spending Data for Statewide Numbers}\label{step-7-aggregating-the-spending-data-for-statewide-numbers}}

Lines 55-56 and 58-60

\hypertarget{step-8-compiling-employment-data}{%
\subsection{Step 8: Compiling Employment Data}\label{step-8-compiling-employment-data}}

Lines ??-??

\hypertarget{step-9-running-for-loops-to-generate-implan-activity-sheets}{%
\subsection{Step 9: Running For Loops to Generate IMPLAN Activity Sheets}\label{step-9-running-for-loops-to-generate-implan-activity-sheets}}

Line ??

\begin{itemize}
\item
  Process data

  \begin{itemize}
  \tightlist
  \item
    Clean contracts and grant data-
  \item
    Clean spending data
  \item
    Error check contract spending data
  \end{itemize}

  Will need to go into detail about changes in the code between this year (2021) and subsequent years

  More detailed mention of how the error checking of the USASpending.gov contract data is needed
  A detailed walk through of how to manually check data and use the multiple NAICS to IMPLAN crosswalks to catch data
  Mention how IMPLAN automatically removes any codes having to do with construction so those have to be manually coded

  Some errors occur due to the transaction not being given a NAICS code, those need to be manually fixed

  Issues occur with NAICS codes that apply to multiple IMPLAN codes- give detailed explanation of how this was worked around and data was processed and added back to the main cleaned data.
\end{itemize}

\hypertarget{using-implan}{%
\chapter{Using IMPLAN}\label{using-implan}}

Once the IMPLAN activity sheets for your desired geographies have been produced, it is time to upload them into IMPLAN and allow the tool to run its analysis. When you log into IMPLAN, the homepage should display 3 boxes to navigate through: Regions, Impacts, and Projects.

\begin{itemize}
\item
  \textbf{Regions:} Click on Regions to begin your analysis. This should open up a map of the United States. Select the region of interest for the analysis (state, county, congressional district, etc.) and give this project a name. After saving the project, move on to the Impacts tab.
\item
  \textbf{Impacts:} In the Impacts tab, look for the button to the right of the ``Save'' button. Click on that, and select ``upload event template''. From there, find the activity sheet for the geography of interest and select that for upload. Ensure that ``Industry Change'' and ``Household Spending'' can be selected, and choose those for uploading into IMPLAN. The data points for the respective IMPLAN sectors should then auto-populate on IMPLAN. If your analysis is including SmartPay spending data, be sure to manually add that in as type ``Institutional Spending'', specification 11001, and the value amount. Choose to select all events (the button to the left of the ``Save'' button) and drag them over to the geography's model on the right side of the IMPLAN screen. After that, select to run the model at the bottom right. Depending on how big the model, IMPLAN will take time to generate the results. Once the model is done with its analysis, click on the ``View Results'' button.
\item
  \textbf{Results:} Once on this page, one can sort through the results of the IMPLAN activity sheet that was ran for a geography and download CSV files of a variety of data points. For this report, the data points of interest included economic indicators like output and full-time employment (FTE) opportunities, both generally and across industries, as well as government and tax revenue generated.
\end{itemize}

As part of our final step before developing and writing the reports, our team created code to combine all the input and output data from IMPLAN into one big spreadsheet which was used to create the graphs and charts seen throughout the reports.

\hypertarget{conclusion-discussion}{%
\chapter{Conclusion/ Discussion}\label{conclusion-discussion}}

Government spending data is very difficult to obtain and there is not a lot of good documentation to help lay people use this data
Hopefully we provide some guidelines and aid in discovering and processing this data so that quality studies can come about and
Government spending can become more transparent.

Utilizing IMPLAN to manage government spending data doesn't come with a lot of instructions

You have to trust that the data entry is accurate, many instances of older NAICS codes exist and this has the potential to introduce errors into the code.

Limited time to process the data due to a new method of processing the data

\hypertarget{whats-next}{%
\chapter{What's Next?}\label{whats-next}}

A section on where we hope to add and develop this process. Potentially the section to outline changes to the code we have already made for the upcoming 2021 report.

\hypertarget{license-your-gitbook}{%
\chapter{License your GitBook}\label{license-your-gitbook}}

In the spirit of Open Science, it is good to think about making your course materials Open Source. That means that other people can use them. In principle, if you publish materials online without license information, you hold the copyright to those materials. If you want them to be Open Source, you must include a license. It is not always obvious what license to choose.

The Creative Commons licenses are typically suitable for course materials. This GitBook, for example, is licensed under CC-BY 4.0. That means you can use and remix it as you like, but you must credit the original source.

If your project is more focused on software or source code, consider using the \href{https://www.gnu.org/licenses/gpl-3.0.en.html}{GNU GPL v3 license} instead.

You can find \href{https://creativecommons.org/share-your-work/licensing-examples}{more information about the Creative Commons Licenses here}. Specific licenses that might be useful are:

\begin{itemize}
\tightlist
\item
  \href{https://creativecommons.org/share-your-work/public-domain/cc0/}{CC0 (``No Rights Reserved'')}, everybody can do what they want with your work.
\item
  \href{https://creativecommons.org/licenses/by/4.0/}{CC-BY 4.0 (``Attribution'')}, everybody can do what they want with your work, but they must credit you. Note that this license may not be suitable for software or source code!
\end{itemize}

For compatibility between CC and GNU licenses, see \href{https://creativecommons.org/faq/\#Can_I_apply_a_Creative_Commons_license_to_software.3F}{this FAQ}.

  \bibliography{literature.bib}

\end{document}
